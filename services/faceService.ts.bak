// Face Recognition Service - Communicates with DeepFace Docker API

const BACKEND_URL = '/deepface';

export interface FaceRegistrationResult {
    success: boolean;
    embeddings?: number[];
    liveness_verified?: boolean;
    message: string;
}

export interface FaceVerificationResult {
    match: boolean;
    confidence: number;
    distance?: number;
    message: string;
}

function checkLiveness(frames: string[]): { ok: boolean; message?: string } {
    if (!frames || frames.length < 3) {
        return {
            ok: false,
            message: 'At least 3 frames are required for liveness detection.',
        };
    }

    const uniqueFrames = new Set(frames);
    if (uniqueFrames.size < 2) {
        return {
            ok: false,
            message: 'Frames are too similar. Please move your head and blink as instructed.',
        };
    }

    return { ok: true };
}

function computeDistance(a: number[], b: number[]): number {
    if (!a || !b || a.length === 0 || b.length === 0 || a.length !== b.length) {
        throw new Error('Invalid or mismatched face embeddings.');
    }

    let sum = 0;
    for (let i = 0; i < a.length; i++) {
        const diff = a[i] - b[i];
        sum += diff * diff;
    }
    return Math.sqrt(sum);
}

function distanceToConfidence(distance: number): number {
    const confidence = 1 - distance / 20.0;
    return Math.max(0, Math.min(1, confidence));
}

/**
 * SECURITY: Detect and count faces in an image
 * Returns the number of faces detected and throws error if not exactly 1 face
 */
export async function detectAndCountFaces(base64Frame: string): Promise<{ faceCount: number; message: string }> {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 30000);

    try {
        const response = await fetch(`${BACKEND_URL}/represent`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({
                img_path: `data:image/jpeg;base64,${base64Frame}`,
                model_name: 'Facenet',
                detector_backend: 'opencv',
                enforce_detection: true, // STRICT: Must detect faces
            }),
            signal: controller.signal
        });

        clearTimeout(timeoutId);
        const data = await response.json();

        console.log('Face Detection Response:', JSON.stringify(data, null, 2));

        // Count faces from response
        let faceCount = 0;

        if (data.results && Array.isArray(data.results)) {
            faceCount = data.results.length;
        } else if (Array.isArray(data)) {
            faceCount = data.length;
        }

        // SECURITY VALIDATION
        if (faceCount === 0) {
            return {
                faceCount: 0,
                message: 'No face detected. Please ensure your face is clearly visible and well-lit.'
            };
        } else if (faceCount > 1) {
            return {
                faceCount,
                message: `Multiple faces detected (${faceCount} people). Please ensure only you are visible in the frame.`
            };
        }

        return {
            faceCount: 1,
            message: 'Single face detected successfully.'
        };

    } catch (err: any) {
        if (err.name === 'AbortError') {
            throw new Error('Face detection timed out. Please try again.');
        }

        // Handle "Face could not be detected" error from DeepFace
        if (err.message?.includes('Face could not be detected') || err.message?.includes('no face')) {
            return {
                faceCount: 0,
                message: 'No face detected. Please ensure your face is clearly visible, well-lit, and centered in the frame.'
            };
        }

        throw new Error(`Face detection failed: ${err.message || 'Unknown error'}`);
    } finally {
        clearTimeout(timeoutId);
    }
}

async function getEmbeddingFromDocker(base64Frame: string, skipFaceCountCheck: boolean = false): Promise<number[]> {
    // SECURITY: Check for multiple faces BEFORE processing embeddings
    if (!skipFaceCountCheck) {
        const faceCheck = await detectAndCountFaces(base64Frame);
        if (faceCheck.faceCount !== 1) {
            throw new Error(faceCheck.message);
        }
    }

    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 30000); // 30 second timeout (balanced for speed + reliability)

    let response;
    try {
        response = await fetch(`${BACKEND_URL}/represent`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({
                img_path: `data:image/jpeg;base64,${base64Frame}`,
                model_name: 'Facenet',
                detector_backend: 'opencv',
                enforce_detection: true, // STRICT: Changed to true for security
            }),
            signal: controller.signal
        });
    } catch (err: any) {
        if (err.name === 'AbortError') {
            throw new Error('Face recognition service timed out (30s). Please try again.');
        }
        throw err;
    } finally {
        clearTimeout(timeoutId);
    }

    const data = await response.json();

    console.log('DeepFace /represent response:', JSON.stringify(data, null, 2));

    if (!response.ok) {
        const errorMsg = data?.error || data?.message || 'DeepFace /represent request failed';
        throw new Error(errorMsg);
    }

    let embedding: number[] | undefined;

    // DeepFace API returns: { results: [ { embedding: [...], ... } ] }
    if (data.results && Array.isArray(data.results) && data.results.length > 0) {
        const first = data.results[0];
        if (first && Array.isArray(first.embedding)) {
            embedding = first.embedding;
        }
    }
    // Fallback: direct array format (older API versions)
    else if (Array.isArray(data)) {
        const first = data[0];
        if (first && Array.isArray(first.embedding)) {
            embedding = first.embedding;
        }
    }
    // Fallback: flat embedding format
    else if (Array.isArray(data.embedding)) {
        embedding = data.embedding;
    }

    if (!embedding || embedding.length === 0) {
        throw new Error(`Could not extract face embedding from DeepFace response. Response structure: ${JSON.stringify(Object.keys(data))}`);
    }

    return embedding;
}

// Helper for single-image embedding extraction from other parts of the app
export async function getEmbeddingForBase64Image(base64Image: string): Promise<number[]> {
    return getEmbeddingFromDocker(base64Image);
}

export async function checkBackendHealth(): Promise<boolean> {
    try {
        const response = await fetch(`${BACKEND_URL}/`, {
            method: 'GET',
        });
        return response.ok;
    } catch (error) {
        console.error('DeepFace Docker health check failed:', error);
        return false;
    }
}

export async function registerFace(
    userId: string,
    frames: string[],
): Promise<FaceRegistrationResult> {
    try {
        const liveness = checkLiveness(frames);
        if (!liveness.ok) {
            return {
                success: false,
                message: liveness.message || 'Liveness check failed.',
            };
        }

        const middleIndex = Math.floor(frames.length / 2);
        const middleFrame = frames[middleIndex];

        const embedding = await getEmbeddingFromDocker(middleFrame);

        return {
            success: true,
            embeddings: embedding,
            liveness_verified: true,
            message: 'Face registered successfully',
        };
    } catch (error: any) {
        console.error('Face registration error via DeepFace Docker:', error);
        return {
            success: false,
            message:
                error?.message ||
                'Could not connect to face recognition service. Make sure the DeepFace Docker container is running on port 5000.',
        };
    }
}

export async function verifyFace(
    liveFrames: string[],
    storedEmbedding: number[],
): Promise<FaceVerificationResult> {
    try {
        const liveness = checkLiveness(liveFrames);
        if (!liveness.ok) {
            return {
                match: false,
                confidence: 0,
                message: liveness.message || 'Liveness check failed.',
            };
        }

        if (!storedEmbedding || storedEmbedding.length === 0) {
            return {
                match: false,
                confidence: 0,
                message: 'No stored face embedding found for this user.',
            };
        }

        const middleIndex = Math.floor(liveFrames.length / 2);
        const liveFrame = liveFrames[middleIndex];

        const liveEmbedding = await getEmbeddingFromDocker(liveFrame);

        const distance = computeDistance(storedEmbedding, liveEmbedding);
        const threshold = 10.0;
        const match = distance < threshold;
        const confidence = distanceToConfidence(distance);

        return {
            match,
            confidence,
            distance: Number(distance.toFixed(3)),
            message: match ? 'Face verified successfully' : 'Face verification failed',
        };
    } catch (error: any) {
        console.error('Face verification error via DeepFace Docker:', error);
        return {
            match: false,
            confidence: 0,
            message:
                error?.message ||
                'Could not connect to face recognition service. Make sure the DeepFace Docker container is running on port 5000.',
        };
    }
}

async function urlToBase64(url: string): Promise<string> {
    try {
        const response = await fetch(url);
        const blob = await response.blob();
        return new Promise((resolve, reject) => {
            const reader = new FileReader();
            reader.onloadend = () => {
                const base64String = reader.result as string;
                // Remove data:image/jpeg;base64, prefix if present
                const base64Content = base64String.includes(',') ? base64String.split(',')[1] : base64String;
                resolve(base64Content);
            };
            reader.onerror = reject;
            reader.readAsDataURL(blob);
        });
    } catch (e) {
        console.error("Failed to convert URL to base64", e);
        throw new Error("Could not download ID document.");
    }
}


export async function verifyIdentityAgainstDoc(
    liveFaceBase64: string,
    docData: string, // Can be URL or Base64 (cleaned)
    existingLiveEmbedding?: number[],
    existingDocEmbedding?: number[]
): Promise<{ verified: boolean; confidence: number; message: string }> {
    try {
        // 1. Get Live Face Embedding (WITH face count check for security)
        // Use existing embedding if provided to save a call, otherwise compute it
        let liveEmbedding = existingLiveEmbedding;
        if (!liveEmbedding) {
            liveEmbedding = await getEmbeddingFromDocker(liveFaceBase64, false); // Enforce face count check
        }

        // 2. Get Doc Face Embedding (SKIP face count check for ID documents)
        let docEmbedding = existingDocEmbedding;

        if (!docEmbedding) {
            let docBase64 = docData;
            // If it looks like a URL, download it (fallback support)
            if (docData.startsWith('http')) {
                console.log('Fetching ID document via URL for verification...');
                docBase64 = await urlToBase64(docData);
            } else {
                console.log('Using provided base64 ID document for verification...');
            }
            // Skip face count check for documents (they may have different formats)
            docEmbedding = await getEmbeddingFromDocker(docBase64, true);
        } else {
            console.log('Using existing document embedding for verification...');
        }

        // 3. Compare
        const distance = computeDistance(liveEmbedding!, docEmbedding);
        const confidence = distanceToConfidence(distance);

        // Stricter threshold for auto-approval (e.g., 90% confidence or distance < 10)
        // distance < 10 is the same as verifyFace
        const isMatch = distance < 10.0;

        return {
            verified: isMatch,
            confidence,
            message: isMatch ? 'Biometric match with ID document.' : 'Face does not match ID document.'
        };

    } catch (error: any) {
        console.error('AI Auto-Approval Failed:', error);
        return {
            verified: false,
            confidence: 0,
            message: 'Could not automatically verify against ID document. Manual review required.'
        };
    }
}
